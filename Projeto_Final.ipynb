{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint\n",
    "from tensorflow import keras \n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "ds = pd.read_csv('TRNcod.xls', delimiter = \"\\t\")\n",
    "\n",
    "# Shuffle no dataset\n",
    "ds = ds.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([d for d in ds.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanhos de inadimplentes: \n",
      "Treino: 127549\n",
      "Teste: 33524\n",
      "Validação: 63775\n",
      "\n",
      "Tamanhos de adimplentes: \n",
      "Treino: 127549\n",
      "Teste: 63774\n",
      "Validação: 63775\n",
      "\n",
      "Colunas: 246\n"
     ]
    }
   ],
   "source": [
    "# inadimplentes = pd.DataFrame(list(filter(lambda x: x == 1, ds['IND_BOM_1_2'])))\n",
    "\n",
    "# Selecionando quem é inadimplente\n",
    "inadimplentes = ds[ds['IND_BOM_1_2'] == 1]\n",
    "\n",
    "# Selecionando quem é adimplente\n",
    "adimplente = ds[ds['IND_BOM_1_2'] == 0]\n",
    "\n",
    "global treino_ina\n",
    "global teste_ina\n",
    "global valid_ina\n",
    "global treino_adi\n",
    "global teste_adi\n",
    "global valid_adi\n",
    "\n",
    "\n",
    "# Dividindo datasets\n",
    "treino_ina = inadimplentes[:int(len(inadimplentes)/2)]\n",
    "teste_ina  = inadimplentes[int(len(inadimplentes)/2):int((len(inadimplentes)*3)/4)]\n",
    "valid_ina  = inadimplentes[int((len(inadimplentes)*3)/4):]\n",
    "\n",
    "treino_adi = adimplente[:int(len(adimplente)/2)]\n",
    "teste_adi  = adimplente[int(len(adimplente)/2):int((len(adimplente)*3)/4)]\n",
    "valid_adi  = adimplente[int((len(adimplente)*3)/4):]\n",
    "\n",
    "# Equalizando tamanho de datasets treino e validação dos inadimplentes ao de adimplentes\n",
    "treino_ina = treino_ina.loc[treino_ina.index.repeat(2)].drop('INDEX', axis=1)\n",
    "treino_ina[\"COPIA\"] = treino_ina.duplicated()\n",
    "treino_ina.sort_values(by=\"COPIA\", inplace=True, ignore_index=True)\n",
    "treino_ina = treino_ina.iloc[ : ( len(treino_adi) - len(treino_ina) ), :  ]\n",
    "treino_ina.drop(columns=[\"COPIA\"], axis=1)\n",
    "\n",
    "valid_ina  = valid_ina.loc[valid_ina.index.repeat(2)].drop('INDEX', axis=1)\n",
    "valid_ina[\"COPIA\"] = valid_ina.duplicated()\n",
    "valid_ina.sort_values(by=\"COPIA\", inplace=True, ignore_index=True)\n",
    "valid_ina = valid_ina.iloc[ : ( len(valid_adi) - len(valid_ina) ), :  ]\n",
    "valid_ina.drop(columns=[\"COPIA\"], axis=1)\n",
    "# Fim da equalização\n",
    "\n",
    "print('Tamanhos de inadimplentes: \\nTreino: {}\\nTeste: {}\\nValidação: {}\\n'.format(len(treino_ina.values), len(teste_ina.values), len(valid_ina.values)))\n",
    "print('Tamanhos de adimplentes: \\nTreino: {}\\nTeste: {}\\nValidação: {}\\n'.format(len(treino_adi.values), len(teste_adi.values), len(valid_adi.values)))\n",
    "print('Colunas: {}'.format(len([d for d in ds.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/29294983/how-to-calculate-correlation-between-all-columns-and-remove-highly-correlated-on\n",
    "\n",
    "# # Create correlation matrix\n",
    "# corr_matrix = ds.corr().abs()\n",
    "\n",
    "# # Select upper triangle of correlation matrix\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# # Find features with correlation greater than 0.89\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.89)]\n",
    "\n",
    "# # Drop features \n",
    "# # ds.drop(to_drop, axis=1, inplace=True)\n",
    "# ds.columns\n",
    "\n",
    "\n",
    "# Colunas mais correlacionadas\n",
    "# l = []\n",
    "# for c in ds.columns[:-1]:\n",
    "#     l.append({c: ds[c].corr(ds['IND_BOM_1_1'])})\n",
    "#     # if (ds[c].corr(ds['IND_BOM_1_1']) > 0.0):\n",
    "#         # print( c, ds[c].corr(ds['IND_BOM_1_1']) )\n",
    "# l.sort(key=lambda x: list(x.values())[0])\n",
    "# print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passos a fazer\n",
    "# Esquema de experimentação (passo a passo do que vamos testar)\n",
    "# MLP & Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "12163/12163 [==============================] - 8s 631us/step - loss: 0.6016 - accuracy: 0.6719\n",
      "Epoch 2/10000\n",
      "12163/12163 [==============================] - 8s 619us/step - loss: 0.5938 - accuracy: 0.6783\n",
      "Epoch 3/10000\n",
      "12163/12163 [==============================] - 8s 622us/step - loss: 0.5920 - accuracy: 0.6793\n",
      "Epoch 4/10000\n",
      "12163/12163 [==============================] - 8s 618us/step - loss: 0.5906 - accuracy: 0.6807\n",
      "Epoch 5/10000\n",
      "12163/12163 [==============================] - 8s 619us/step - loss: 0.5898 - accuracy: 0.6806\n",
      "Epoch 6/10000\n",
      "11979/12163 [============================>.] - ETA: 0s - loss: 0.5889 - accuracy: 0.6820"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9676268b4ccc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mparadinha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparadinha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1092\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "\n",
    "# MLP\n",
    "model = Sequential()\n",
    "\n",
    "# Dropout\n",
    "layer = Dropout(randint(0,100)/100)\n",
    "\n",
    "# Regularização\n",
    "# ???\n",
    "\n",
    "ds_2 = ds\n",
    "# ds_2 = ds.iloc[ 0:300, : ]\n",
    "\n",
    "trY = ds_2['IND_BOM_1_2']\n",
    "trX = ds_2.drop('IND_BOM_1_2', axis=1)\n",
    "trX = trX.drop('IND_BOM_1_1', axis=1)\n",
    "trX = trX.drop('INDEX', axis=1)\n",
    "\n",
    "# Taxa de parada quando não mais evoluir\n",
    "\n",
    "model.add(Dense(32,input_dim=243, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "\n",
    "\n",
    "# Parada antecipada caso em 10 epochs ela deixe de melhorar\n",
    "paradinha = EarlyStopping(monitor='accuracy', mode='max', patience=10)\n",
    "\n",
    "history = model.fit(trX, trY, epochs=10000, verbose=1, callbacks=[paradinha])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "313/313 [==============================] - 0s 668us/step - loss: 0.6424 - accuracy: 0.6427\n",
      "Epoch 2/10000\n",
      "313/313 [==============================] - 0s 722us/step - loss: 0.6202 - accuracy: 0.6583\n",
      "Epoch 3/10000\n",
      "313/313 [==============================] - 0s 719us/step - loss: 0.6131 - accuracy: 0.6657\n",
      "Epoch 4/10000\n",
      "313/313 [==============================] - 0s 725us/step - loss: 0.6050 - accuracy: 0.6729\n",
      "Epoch 5/10000\n",
      "313/313 [==============================] - 0s 719us/step - loss: 0.6000 - accuracy: 0.6749\n",
      "Epoch 6/10000\n",
      "313/313 [==============================] - 0s 770us/step - loss: 0.5966 - accuracy: 0.6797\n",
      "Epoch 7/10000\n",
      "313/313 [==============================] - 0s 827us/step - loss: 0.5913 - accuracy: 0.6815\n",
      "Epoch 8/10000\n",
      "313/313 [==============================] - 0s 725us/step - loss: 0.5886 - accuracy: 0.6838\n",
      "Epoch 9/10000\n",
      "313/313 [==============================] - 0s 658us/step - loss: 0.5840 - accuracy: 0.6915\n",
      "Epoch 10/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.5809 - accuracy: 0.6927\n",
      "Epoch 11/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.5747 - accuracy: 0.6985\n",
      "Epoch 12/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.5725 - accuracy: 0.6955\n",
      "Epoch 13/10000\n",
      "313/313 [==============================] - 0s 658us/step - loss: 0.5683 - accuracy: 0.7053\n",
      "Epoch 14/10000\n",
      "313/313 [==============================] - 0s 671us/step - loss: 0.5674 - accuracy: 0.7033\n",
      "Epoch 15/10000\n",
      "313/313 [==============================] - 0s 681us/step - loss: 0.5617 - accuracy: 0.7074\n",
      "Epoch 16/10000\n",
      "313/313 [==============================] - 0s 661us/step - loss: 0.5596 - accuracy: 0.7138\n",
      "Epoch 17/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.5553 - accuracy: 0.7125\n",
      "Epoch 18/10000\n",
      "313/313 [==============================] - 0s 658us/step - loss: 0.5532 - accuracy: 0.7198\n",
      "Epoch 19/10000\n",
      "313/313 [==============================] - 0s 658us/step - loss: 0.5480 - accuracy: 0.7217\n",
      "Epoch 20/10000\n",
      "313/313 [==============================] - 0s 652us/step - loss: 0.5455 - accuracy: 0.7241\n",
      "Epoch 21/10000\n",
      "313/313 [==============================] - 0s 681us/step - loss: 0.5426 - accuracy: 0.7233\n",
      "Epoch 22/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.5384 - accuracy: 0.7294\n",
      "Epoch 23/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.5348 - accuracy: 0.7335\n",
      "Epoch 24/10000\n",
      "313/313 [==============================] - 0s 674us/step - loss: 0.5327 - accuracy: 0.7310\n",
      "Epoch 25/10000\n",
      "313/313 [==============================] - 0s 677us/step - loss: 0.5327 - accuracy: 0.7325\n",
      "Epoch 26/10000\n",
      "313/313 [==============================] - 0s 684us/step - loss: 0.5246 - accuracy: 0.7370\n",
      "Epoch 27/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.5242 - accuracy: 0.7379\n",
      "Epoch 28/10000\n",
      "313/313 [==============================] - 0s 661us/step - loss: 0.5200 - accuracy: 0.7432\n",
      "Epoch 29/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.5178 - accuracy: 0.7458\n",
      "Epoch 30/10000\n",
      "313/313 [==============================] - 0s 700us/step - loss: 0.5147 - accuracy: 0.7428\n",
      "Epoch 31/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.5121 - accuracy: 0.7485\n",
      "Epoch 32/10000\n",
      "313/313 [==============================] - 0s 661us/step - loss: 0.5095 - accuracy: 0.7526\n",
      "Epoch 33/10000\n",
      "313/313 [==============================] - 0s 674us/step - loss: 0.5051 - accuracy: 0.7582\n",
      "Epoch 34/10000\n",
      "313/313 [==============================] - 0s 719us/step - loss: 0.5011 - accuracy: 0.7572\n",
      "Epoch 35/10000\n",
      "313/313 [==============================] - 0s 658us/step - loss: 0.4988 - accuracy: 0.7574\n",
      "Epoch 36/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.5004 - accuracy: 0.7550\n",
      "Epoch 37/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.4963 - accuracy: 0.7601\n",
      "Epoch 38/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.4919 - accuracy: 0.7629\n",
      "Epoch 39/10000\n",
      "313/313 [==============================] - 0s 658us/step - loss: 0.4916 - accuracy: 0.7628\n",
      "Epoch 40/10000\n",
      "313/313 [==============================] - 0s 652us/step - loss: 0.4850 - accuracy: 0.7709\n",
      "Epoch 41/10000\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.4823 - accuracy: 0.7697\n",
      "Epoch 42/10000\n",
      "313/313 [==============================] - 0s 626us/step - loss: 0.4789 - accuracy: 0.7730\n",
      "Epoch 43/10000\n",
      "313/313 [==============================] - 0s 629us/step - loss: 0.4773 - accuracy: 0.7722\n",
      "Epoch 44/10000\n",
      "313/313 [==============================] - 0s 681us/step - loss: 0.4765 - accuracy: 0.7709\n",
      "Epoch 45/10000\n",
      "313/313 [==============================] - 0s 725us/step - loss: 0.4727 - accuracy: 0.7771\n",
      "Epoch 46/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.4669 - accuracy: 0.7812\n",
      "Epoch 47/10000\n",
      "313/313 [==============================] - 0s 671us/step - loss: 0.4682 - accuracy: 0.7754\n",
      "Epoch 48/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.4666 - accuracy: 0.7802\n",
      "Epoch 49/10000\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.4659 - accuracy: 0.7795\n",
      "Epoch 50/10000\n",
      "313/313 [==============================] - 0s 677us/step - loss: 0.4590 - accuracy: 0.7897\n",
      "Epoch 51/10000\n",
      "313/313 [==============================] - 0s 652us/step - loss: 0.4598 - accuracy: 0.7860\n",
      "Epoch 52/10000\n",
      "313/313 [==============================] - 0s 674us/step - loss: 0.4583 - accuracy: 0.7815\n",
      "Epoch 53/10000\n",
      "313/313 [==============================] - 0s 872us/step - loss: 0.4568 - accuracy: 0.7843\n",
      "Epoch 54/10000\n",
      "313/313 [==============================] - 0s 773us/step - loss: 0.4507 - accuracy: 0.7918\n",
      "Epoch 55/10000\n",
      "313/313 [==============================] - 0s 748us/step - loss: 0.4525 - accuracy: 0.7889\n",
      "Epoch 56/10000\n",
      "313/313 [==============================] - 0s 927us/step - loss: 0.4430 - accuracy: 0.7935\n",
      "Epoch 57/10000\n",
      "313/313 [==============================] - 0s 687us/step - loss: 0.4483 - accuracy: 0.7927\n",
      "Epoch 58/10000\n",
      "313/313 [==============================] - 0s 834us/step - loss: 0.4455 - accuracy: 0.7941\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 805us/step - loss: 0.4469 - accuracy: 0.7919\n",
      "Epoch 60/10000\n",
      "313/313 [==============================] - 0s 700us/step - loss: 0.4403 - accuracy: 0.7994\n",
      "Epoch 61/10000\n",
      "313/313 [==============================] - 0s 773us/step - loss: 0.4383 - accuracy: 0.7949\n",
      "Epoch 62/10000\n",
      "313/313 [==============================] - 0s 738us/step - loss: 0.4367 - accuracy: 0.8010\n",
      "Epoch 63/10000\n",
      "313/313 [==============================] - 0s 760us/step - loss: 0.4361 - accuracy: 0.7987\n",
      "Epoch 64/10000\n",
      "313/313 [==============================] - 0s 767us/step - loss: 0.4343 - accuracy: 0.7995\n",
      "Epoch 65/10000\n",
      "313/313 [==============================] - 0s 687us/step - loss: 0.4314 - accuracy: 0.8010\n",
      "Epoch 66/10000\n",
      "313/313 [==============================] - 0s 728us/step - loss: 0.4311 - accuracy: 0.8009\n",
      "Epoch 67/10000\n",
      "313/313 [==============================] - 0s 684us/step - loss: 0.4243 - accuracy: 0.8053\n",
      "Epoch 68/10000\n",
      "313/313 [==============================] - 0s 754us/step - loss: 0.4258 - accuracy: 0.8037\n",
      "Epoch 69/10000\n",
      "313/313 [==============================] - 0s 738us/step - loss: 0.4230 - accuracy: 0.8064\n",
      "Epoch 70/10000\n",
      "313/313 [==============================] - 0s 776us/step - loss: 0.4239 - accuracy: 0.80390s - loss: 0.4213 - accuracy: 0.\n",
      "Epoch 71/10000\n",
      "313/313 [==============================] - 0s 703us/step - loss: 0.4202 - accuracy: 0.8109\n",
      "Epoch 72/10000\n",
      "313/313 [==============================] - 0s 681us/step - loss: 0.4230 - accuracy: 0.8060\n",
      "Epoch 73/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.4211 - accuracy: 0.8063\n",
      "Epoch 74/10000\n",
      "313/313 [==============================] - 0s 796us/step - loss: 0.4175 - accuracy: 0.8098\n",
      "Epoch 75/10000\n",
      "313/313 [==============================] - 0s 709us/step - loss: 0.4161 - accuracy: 0.8093\n",
      "Epoch 76/10000\n",
      "313/313 [==============================] - 0s 875us/step - loss: 0.4097 - accuracy: 0.8156\n",
      "Epoch 77/10000\n",
      "313/313 [==============================] - 0s 974us/step - loss: 0.4088 - accuracy: 0.8141\n",
      "Epoch 78/10000\n",
      "313/313 [==============================] - 0s 767us/step - loss: 0.4110 - accuracy: 0.8119\n",
      "Epoch 79/10000\n",
      "313/313 [==============================] - 0s 725us/step - loss: 0.4056 - accuracy: 0.8172\n",
      "Epoch 80/10000\n",
      "313/313 [==============================] - 0s 700us/step - loss: 0.4068 - accuracy: 0.8139\n",
      "Epoch 81/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.4088 - accuracy: 0.8137\n",
      "Epoch 82/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.4092 - accuracy: 0.8162\n",
      "Epoch 83/10000\n",
      "313/313 [==============================] - 0s 674us/step - loss: 0.4067 - accuracy: 0.8147\n",
      "Epoch 84/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.4014 - accuracy: 0.8216\n",
      "Epoch 85/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3956 - accuracy: 0.8186\n",
      "Epoch 86/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3966 - accuracy: 0.8246\n",
      "Epoch 87/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3977 - accuracy: 0.8220\n",
      "Epoch 88/10000\n",
      "313/313 [==============================] - 0s 668us/step - loss: 0.3957 - accuracy: 0.8230\n",
      "Epoch 89/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3923 - accuracy: 0.8222\n",
      "Epoch 90/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3889 - accuracy: 0.8258\n",
      "Epoch 91/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3917 - accuracy: 0.8254\n",
      "Epoch 92/10000\n",
      "313/313 [==============================] - 0s 629us/step - loss: 0.3914 - accuracy: 0.8265\n",
      "Epoch 93/10000\n",
      "313/313 [==============================] - 0s 658us/step - loss: 0.3891 - accuracy: 0.8286\n",
      "Epoch 94/10000\n",
      "313/313 [==============================] - 0s 668us/step - loss: 0.3893 - accuracy: 0.8289\n",
      "Epoch 95/10000\n",
      "313/313 [==============================] - 0s 735us/step - loss: 0.3780 - accuracy: 0.8337\n",
      "Epoch 96/10000\n",
      "313/313 [==============================] - 0s 645us/step - loss: 0.3814 - accuracy: 0.8289\n",
      "Epoch 97/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3818 - accuracy: 0.8321\n",
      "Epoch 98/10000\n",
      "313/313 [==============================] - 0s 684us/step - loss: 0.3810 - accuracy: 0.8314\n",
      "Epoch 99/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3851 - accuracy: 0.8272\n",
      "Epoch 100/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3837 - accuracy: 0.8319\n",
      "Epoch 101/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.3793 - accuracy: 0.8290\n",
      "Epoch 102/10000\n",
      "313/313 [==============================] - 0s 690us/step - loss: 0.3765 - accuracy: 0.8353\n",
      "Epoch 103/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.3742 - accuracy: 0.8340\n",
      "Epoch 104/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3746 - accuracy: 0.8342\n",
      "Epoch 105/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.3763 - accuracy: 0.8334\n",
      "Epoch 106/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3697 - accuracy: 0.8401\n",
      "Epoch 107/10000\n",
      "313/313 [==============================] - 0s 671us/step - loss: 0.3678 - accuracy: 0.8400\n",
      "Epoch 108/10000\n",
      "313/313 [==============================] - 0s 652us/step - loss: 0.3719 - accuracy: 0.8364\n",
      "Epoch 109/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3717 - accuracy: 0.8361\n",
      "Epoch 110/10000\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.3653 - accuracy: 0.8379\n",
      "Epoch 111/10000\n",
      "313/313 [==============================] - 0s 629us/step - loss: 0.3665 - accuracy: 0.8385\n",
      "Epoch 112/10000\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.3656 - accuracy: 0.8353\n",
      "Epoch 113/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3666 - accuracy: 0.8392\n",
      "Epoch 114/10000\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.3636 - accuracy: 0.8384\n",
      "Epoch 115/10000\n",
      "313/313 [==============================] - 0s 652us/step - loss: 0.3633 - accuracy: 0.8385\n",
      "Epoch 116/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3559 - accuracy: 0.8454\n",
      "Epoch 117/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.3606 - accuracy: 0.8377\n",
      "Epoch 118/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3587 - accuracy: 0.8403\n",
      "Epoch 119/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3608 - accuracy: 0.8380\n",
      "Epoch 120/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.3626 - accuracy: 0.8354\n",
      "Epoch 121/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3478 - accuracy: 0.8482\n",
      "Epoch 122/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.3547 - accuracy: 0.8489\n",
      "Epoch 123/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3479 - accuracy: 0.8458\n",
      "Epoch 124/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3501 - accuracy: 0.8463\n",
      "Epoch 125/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.3527 - accuracy: 0.8483\n",
      "Epoch 126/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3486 - accuracy: 0.8481\n",
      "Epoch 127/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.3488 - accuracy: 0.8487\n",
      "Epoch 128/10000\n",
      "313/313 [==============================] - 0s 655us/step - loss: 0.3459 - accuracy: 0.8497\n",
      "Epoch 129/10000\n",
      "313/313 [==============================] - 0s 652us/step - loss: 0.3493 - accuracy: 0.8435\n",
      "Epoch 130/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3442 - accuracy: 0.8487\n",
      "Epoch 131/10000\n",
      "313/313 [==============================] - 0s 696us/step - loss: 0.3414 - accuracy: 0.8501\n",
      "Epoch 132/10000\n",
      "313/313 [==============================] - 0s 712us/step - loss: 0.3398 - accuracy: 0.8524\n",
      "Epoch 133/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3408 - accuracy: 0.8494\n",
      "Epoch 134/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3416 - accuracy: 0.8502\n",
      "Epoch 135/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.3357 - accuracy: 0.8570\n",
      "Epoch 136/10000\n",
      "313/313 [==============================] - 0s 629us/step - loss: 0.3432 - accuracy: 0.8517\n",
      "Epoch 137/10000\n",
      "313/313 [==============================] - 0s 658us/step - loss: 0.3458 - accuracy: 0.8498\n",
      "Epoch 138/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3414 - accuracy: 0.8511\n",
      "Epoch 139/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3385 - accuracy: 0.8547\n",
      "Epoch 140/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3319 - accuracy: 0.8591\n",
      "Epoch 141/10000\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.3345 - accuracy: 0.8528\n",
      "Epoch 142/10000\n",
      "313/313 [==============================] - 0s 681us/step - loss: 0.3374 - accuracy: 0.8547\n",
      "Epoch 143/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3318 - accuracy: 0.8542\n",
      "Epoch 144/10000\n",
      "313/313 [==============================] - 0s 636us/step - loss: 0.3337 - accuracy: 0.8540\n",
      "Epoch 145/10000\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.3328 - accuracy: 0.8569\n",
      "Epoch 146/10000\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.3302 - accuracy: 0.8546\n",
      "Epoch 147/10000\n",
      "313/313 [==============================] - 0s 671us/step - loss: 0.3302 - accuracy: 0.8547\n",
      "Epoch 148/10000\n",
      "313/313 [==============================] - 0s 649us/step - loss: 0.3249 - accuracy: 0.8622\n",
      "Epoch 149/10000\n",
      "313/313 [==============================] - 0s 652us/step - loss: 0.3308 - accuracy: 0.8594\n",
      "Epoch 150/10000\n",
      "313/313 [==============================] - 0s 645us/step - loss: 0.3311 - accuracy: 0.8561\n",
      "Epoch 151/10000\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3280 - accuracy: 0.8575\n",
      "Epoch 152/10000\n",
      "313/313 [==============================] - 0s 712us/step - loss: 0.3286 - accuracy: 0.8603\n",
      "Epoch 153/10000\n",
      "313/313 [==============================] - 0s 722us/step - loss: 0.3181 - accuracy: 0.8655\n",
      "Epoch 154/10000\n",
      "313/313 [==============================] - 0s 700us/step - loss: 0.3229 - accuracy: 0.8580\n",
      "Epoch 155/10000\n",
      "313/313 [==============================] - 0s 696us/step - loss: 0.3247 - accuracy: 0.8580\n",
      "Epoch 156/10000\n",
      "313/313 [==============================] - 0s 700us/step - loss: 0.3212 - accuracy: 0.8620\n",
      "Epoch 157/10000\n",
      "313/313 [==============================] - 0s 665us/step - loss: 0.3228 - accuracy: 0.8577\n",
      "Epoch 158/10000\n",
      "313/313 [==============================] - 0s 629us/step - loss: 0.3257 - accuracy: 0.8593\n",
      "Epoch 159/10000\n",
      "313/313 [==============================] - 0s 633us/step - loss: 0.3222 - accuracy: 0.8606\n",
      "Epoch 160/10000\n",
      "313/313 [==============================] - 0s 780us/step - loss: 0.3197 - accuracy: 0.8612\n",
      "Epoch 161/10000\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8632\n",
      "Epoch 162/10000\n",
      "313/313 [==============================] - 0s 984us/step - loss: 0.3171 - accuracy: 0.8649\n",
      "Epoch 163/10000\n",
      "313/313 [==============================] - 0s 856us/step - loss: 0.3183 - accuracy: 0.8602\n"
     ]
    }
   ],
   "source": [
    "def mlp_model(neuronios, camadas, dropout, learning_rate, ativacao, otimizador):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuronios,input_dim=243, activation=ativacao))\n",
    "    model.add(Dropout(dropout))\n",
    "    if camadas==2:\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    if otimizador =='adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif otimizador =='SGD':\n",
    "        opt = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif otimizador =='RMSprop':\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif otimizador =='Adadelta':\n",
    "        opt = keras.optimizers.Adadelta(learning_rate=learning_rate)\n",
    "        \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer=opt)\n",
    "    return model\n",
    "\n",
    "n_neuronios = [8, 16, 32, 64, 128, 512, 1024]\n",
    "n_camadas = [1, 2]\n",
    "n_dropout = [0.4, 0.2, 0.1]\n",
    "n_learning_rate = [0.1, 0.01, 0.001]\n",
    "n_ativacao = ['tanh', 'relu']\n",
    "n_otimizador = ['adam', 'SGD', 'RMSprop','Adadelta']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ds_2 = ds\n",
    "ds_2 = ds.iloc[ 0:10000, : ]\n",
    "\n",
    "trY = ds_2['IND_BOM_1_2']\n",
    "trX = ds_2.drop('IND_BOM_1_2', axis=1)\n",
    "trX = trX.drop('IND_BOM_1_1', axis=1)\n",
    "trX = trX.drop('INDEX', axis=1)\n",
    "\n",
    "\n",
    "model = mlp_model(32, 2, 0.1, 0.0005,'relu','adam')\n",
    "\n",
    "paradinha = EarlyStopping(monitor='accuracy', mode='max', patience=10)\n",
    "history = model.fit(trX, trY, epochs=10000, verbose=1, callbacks=[paradinha])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1s 626us/step - loss: 5.3330 - accuracy: 0.6543\n"
     ]
    }
   ],
   "source": [
    "ds_3 = ds.iloc[ 50001:100001, :]\n",
    "trY = ds_3['IND_BOM_1_2']\n",
    "trX = ds_3.drop('IND_BOM_1_2', axis=1)\n",
    "x, y = model.evaluate(trX, trY, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuidado: usar esses parâmetros muito elevados, ou o default (100 estimadores e profundidade ilimitada) vai travar seu computador\n",
    "\n",
    "# Parâmetros default:\n",
    "# n_estimators=100, *,\n",
    "# criterion=\"gini\",\n",
    "# max_depth=None,\n",
    "# min_samples_split=2,\n",
    "# min_samples_leaf=1,\n",
    "# min_weight_fraction_leaf=0.,\n",
    "# max_features=\"auto\",\n",
    "# max_leaf_nodes=None,\n",
    "# min_impurity_decrease=0.,\n",
    "# min_impurity_split=None,\n",
    "# bootstrap=True,\n",
    "# oob_score=False,\n",
    "# n_jobs=None,\n",
    "# random_state=None,\n",
    "# verbose=0,\n",
    "# warm_start=False,\n",
    "# class_weight=None,\n",
    "# ccp_alpha=0.0,\n",
    "# max_samples=None\n",
    "\n",
    "ds_2 = ds.iloc[ 0:10000, : ]\n",
    "\n",
    "x_rf = ds_2.drop(['IND_BOM_1_2','IND_BOM_1_1','INDEX'],axis=1)\n",
    "y_rf = ds_2['IND_BOM_1_2']\n",
    "\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=10, max_depth=8)\n",
    "n_scores = cross_val_score(random_forest, x_rf, y_rf, scoring='accuracy', n_jobs=1, error_score='raise')\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros default:\n",
    "# *,loss='deviance', \n",
    "# learning_rate=0.1, \n",
    "# n_estimators=100,\n",
    "# subsample=1.0, \n",
    "# criterion='friedman_mse', \n",
    "# min_samples_split=2,\n",
    "# min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.,\n",
    "# max_depth=3, \n",
    "# min_impurity_decrease=0.,\n",
    "# min_impurity_split=None, \n",
    "# random_state=None, \n",
    "# max_features=None, verbose=0,\n",
    "# max_leaf_nodes=None, \n",
    "# warm_start=False,\n",
    "# validation_fraction=0.1, \n",
    "# n_iter_no_change=None, \n",
    "# tol=1e-4,\n",
    "# ccp_alpha=0.0\n",
    "\n",
    "gradient_boost = GradientBoostingClassifier(n_estimators = 5, max_depth = 8)\n",
    "n_scores = cross_val_score(gradient_boost, x_rf, y_rf, scoring='accuracy', n_jobs=1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
